"""
Streamlit Interface for OCR-to-RAG Pipeline with Ollama
Simple interface to add context and ask questions using RAG + Qwen

USAGE:
  Windows: run_app.bat
  Linux/Mac: streamlit run app.py

DO NOT RUN: python app.py (won't work!)
"""

import streamlit as st
from src.rag_pipeline import RAGPipeline
import json
from datetime import datetime

# Page configuration
st.set_page_config(
    page_title="RAG Pipeline with Qwen",
    page_icon="ü§ñ",
    layout="wide"
)

# Initialize session state
if 'pipeline' not in st.session_state:
    st.session_state.pipeline = None
    st.session_state.initialized = False
    st.session_state.total_chunks = 0
    st.session_state.chat_history = []

# Title and description
st.title("ü§ñ RAG Pipeline with Qwen")
st.markdown("Add context to the knowledge base and ask questions using RAG + Ollama")

# Sidebar for configuration and stats
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Initialize pipeline button
    if not st.session_state.initialized:
        if st.button("üöÄ Initialize Pipeline", type="primary"):
            with st.spinner("Initializing RAG Pipeline with Qwen..."):
                try:
                    st.session_state.pipeline = RAGPipeline(use_llm=True)
                    st.session_state.initialized = True
                    st.success("‚úÖ Pipeline initialized!")
                except Exception as e:
                    st.error(f"‚ùå Error: {e}")
                    st.info("Make sure Ollama is running: `ollama serve`")
    else:
        st.success("‚úÖ Pipeline Ready")
        
        # Display stats
        st.header("üìä Statistics")
        if st.session_state.pipeline:
            stats = st.session_state.pipeline.get_stats()
            st.metric("Total Documents", stats['total_documents'])
            st.metric("Total Chunks", st.session_state.total_chunks)
            st.info(f"**Model:** {stats['embedding_model']}")
            st.info(f"**LLM:** qwen3:1.7b")
        
        # Reset button
        if st.button("üóëÔ∏è Reset Database", type="secondary"):
            if st.session_state.pipeline:
                st.session_state.pipeline.reset()
                st.session_state.total_chunks = 0
                st.session_state.chat_history = []
                st.success("Database reset!")
                st.rerun()

# Main content area
if st.session_state.initialized:
    # Create tabs
    tab1, tab2, tab3 = st.tabs(["üìù Add Context", "üí¨ Ask Questions", "üìö Chat History"])
    
    # Tab 1: Add Context
    with tab1:
        st.header("Add Context to Knowledge Base")
        
        # Input method selection
        input_method = st.radio(
            "Choose input method:",
            ["Text Input", "JSON Input", "Upload JSON File"],
            horizontal=True
        )
        
        if input_method == "Text Input":
            st.subheader("Enter Text Directly")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                text_input = st.text_area(
                    "Enter your text:",
                    height=200,
                    placeholder="Paste your text here..."
                )
            
            with col2:
                st.write("**Metadata (Optional)**")
                source = st.text_input("Source", placeholder="e.g., document.pdf")
                page = st.text_input("Page", placeholder="e.g., 1")
                category = st.text_input("Category", placeholder="e.g., AI/ML")
            
            if st.button("‚ûï Add to Knowledge Base", type="primary"):
                if text_input.strip():
                    # Create document
                    document = {"text": text_input}
                    if source:
                        document["source"] = source
                    if page:
                        document["page"] = page
                    if category:
                        document["category"] = category
                    
                    with st.spinner("Processing and storing..."):
                        try:
                            chunks = st.session_state.pipeline.ingest_document(document)
                            st.session_state.total_chunks += chunks
                            st.success(f"‚úÖ Added! Created {chunks} chunks")
                        except Exception as e:
                            st.error(f"‚ùå Error: {e}")
                else:
                    st.warning("Please enter some text!")
        
        elif input_method == "JSON Input":
            st.subheader("Enter JSON Directly")
            
            json_example = """[
  {
    "text": "Your text here...",
    "source": "document.pdf",
    "page": 1
  }
]"""
            
            json_input = st.text_area(
                "Enter JSON:",
                height=200,
                placeholder=json_example
            )
            
            if st.button("‚ûï Add JSON to Knowledge Base", type="primary"):
                if json_input.strip():
                    try:
                        documents = json.loads(json_input)
                        if not isinstance(documents, list):
                            documents = [documents]
                        
                        with st.spinner("Processing and storing..."):
                            chunks = st.session_state.pipeline.ingest_documents(documents)
                            st.session_state.total_chunks += chunks
                            st.success(f"‚úÖ Added {len(documents)} documents! Created {chunks} chunks")
                    except json.JSONDecodeError as e:
                        st.error(f"‚ùå Invalid JSON: {e}")
                    except Exception as e:
                        st.error(f"‚ùå Error: {e}")
                else:
                    st.warning("Please enter JSON data!")
        
        else:  # Upload JSON File
            st.subheader("Upload JSON File")
            
            uploaded_file = st.file_uploader(
                "Choose a JSON file",
                type=['json'],
                help="Upload a JSON file with OCR output"
            )
            
            if uploaded_file is not None:
                if st.button("‚ûï Process and Add File", type="primary"):
                    try:
                        # Save uploaded file temporarily
                        temp_path = f"temp_upload_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                        with open(temp_path, 'wb') as f:
                            f.write(uploaded_file.getbuffer())
                        
                        with st.spinner("Processing file..."):
                            chunks = st.session_state.pipeline.ingest_from_json(temp_path)
                            st.session_state.total_chunks += chunks
                            st.success(f"‚úÖ File processed! Created {chunks} chunks")
                        
                        # Clean up temp file
                        import os
                        os.remove(temp_path)
                        
                    except Exception as e:
                        st.error(f"‚ùå Error: {e}")
    
    # Tab 2: Ask Questions
    with tab2:
        st.header("Ask Questions")
        
        if st.session_state.total_chunks == 0:
            st.warning("‚ö†Ô∏è No context in the knowledge base yet. Add some context first!")
        else:
            # Query input
            query = st.text_input(
                "Your question:",
                placeholder="What would you like to know?",
                key="query_input"
            )
            
            col1, col2, col3 = st.columns([1, 1, 2])
            
            with col1:
                top_k = st.slider("Number of sources", 1, 10, 3)
            
            with col2:
                stream = st.checkbox("Stream response", value=True)
            
            if st.button("üîç Ask", type="primary"):
                if query.strip():
                    with st.spinner("Searching knowledge base..."):
                        try:
                            # Generate answer
                            result = st.session_state.pipeline.generate_answer(
                                query=query,
                                top_k=top_k,
                                stream=False  # We'll handle display ourselves
                            )
                            
                            # Display answer
                            st.subheader("üí° Answer")
                            st.markdown(result['answer'])
                            
                            # Display sources
                            st.subheader("üìö Sources")
                            for i, source in enumerate(result['sources'], 1):
                                with st.expander(f"Source {i}: {source['source']} (Page {source['page']}) - Similarity: {source['similarity']}"):
                                    # Get the actual document text from results
                                    results = st.session_state.pipeline.query(query, top_k)
                                    if i <= len(results):
                                        st.text(results[i-1]['document'])
                            
                            # Add to chat history
                            st.session_state.chat_history.append({
                                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                'query': query,
                                'answer': result['answer'],
                                'sources': result['sources']
                            })
                            
                        except Exception as e:
                            st.error(f"‚ùå Error: {e}")
                else:
                    st.warning("Please enter a question!")
    
    # Tab 3: Chat History
    with tab3:
        st.header("Chat History")
        
        if not st.session_state.chat_history:
            st.info("No questions asked yet.")
        else:
            # Display in reverse order (newest first)
            for i, chat in enumerate(reversed(st.session_state.chat_history)):
                with st.expander(f"üïê {chat['timestamp']} - {chat['query'][:50]}..."):
                    st.markdown(f"**Question:** {chat['query']}")
                    st.markdown(f"**Answer:** {chat['answer']}")
                    st.markdown("**Sources:**")
                    for j, source in enumerate(chat['sources'], 1):
                        st.text(f"  {j}. {source['source']} (Page {source['page']}) - {source['similarity']}")
            
            # Clear history button
            if st.button("üóëÔ∏è Clear History"):
                st.session_state.chat_history = []
                st.rerun()

else:
    # Show instructions when not initialized
    st.info("üëà Click **Initialize Pipeline** in the sidebar to get started!")
    
    st.markdown("""
    ### How to use:
    
    1. **Initialize Pipeline** - Click the button in the sidebar
    2. **Add Context** - Go to the "Add Context" tab and add your documents
    3. **Ask Questions** - Go to "Ask Questions" tab and query your knowledge base
    
    ### Requirements:
    
    - Ollama must be running (`ollama serve`)
    - Qwen model must be available (`ollama pull qwen3:1.7b`)
    
    ### Features:
    
    - ‚úÖ Add context via text, JSON, or file upload
    - ‚úÖ Semantic search using embeddings
    - ‚úÖ AI-powered answers using Qwen
    - ‚úÖ Source attribution
    - ‚úÖ Chat history
    """)

# Footer
st.markdown("---")
st.markdown("Built with ‚ù§Ô∏è using Streamlit, ChromaDB, and Ollama")

