# Configuration for OCR-to-RAG Pipeline

# Embedding Model Configuration
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  embedding_dim: 384
  device: "cpu"  # Change to "cuda" if GPU is available

# Text Chunking Configuration
chunking:
  chunk_size: 1000  # Characters per chunk
  chunk_overlap: 200  # Overlap between chunks
  separators:
    - "\n\n"
    - "\n"
    - " "
    - ""

# Vector Database Configuration
vectordb:
  collection_name: "ocr_documents"
  persist_directory: "./data/vectordb"
  distance_metric: "cosine"  # Options: cosine, l2, ip

# RAG Configuration
rag:
  top_k: 5  # Number of documents to retrieve
  score_threshold: 0.5  # Minimum similarity score

# LLM Configuration (Ollama)
llm:
  model_name: "qwen3:1.7b"  # Ollama model name (qwen3:1.7b, gemma3:1b, llama3.2:1b, deepseek-r1:1.5b)
  base_url: "http://localhost:11434"  # Ollama API URL
  temperature: 0.7  # Sampling temperature (0.0 = deterministic, 1.0 = creative)
  max_tokens: 2048  # Maximum tokens to generate

# OCR Processing Configuration
# OCR JSON files are provided by collaborator with text and metadata

# Logging Configuration
logging:
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

